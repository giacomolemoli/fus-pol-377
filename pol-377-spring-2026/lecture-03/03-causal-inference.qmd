---
title: "International Political Economy"
subtitle: "Lecture 3: Introduction to Causal Inference"
date: "2026-01-27"
---

# Causal Inference from a Research Design Perspective {.section}

## Causal research questions
We are now empirical IPE researchers: we use data to answer questions about the world

. . . 

We always start by formulating a research question (RQ). 

::: {.callout-note title="Our research question"}
Do World Bank financing projects increase human development?
:::

 The RQ can be derived from [theory]{.hover-note data-tooltip="e.g., a large theoretical literature in economics studies the causes of local development. WB projects are designed to provide several of the factors of development, so it is natural to study their effects as an application of some theories"} or from a "real-world" [puzzle]{.hover-note data-tooltip="e.g., the WB devotes a lot of resources to projects, so it is necessary to understand if they work as intended."}

. . . 

The RQs we care about are often (but not always) **causal**: we ask *if* WB projects **cause** development and if so, *how much*

. . . 

But what does it mean for a question to be causal? How do we proceed with our empirical study if we want to answer a causal question?

## Causality and counterfactuals

[Causal inference]{.alert} is the process of determining causal effects  

. . . 

The key notion in causal inference is [counterfactual]{.alert}: what would have happened to a unit in an alternative state of the world where the "cause" we want to study did not happen

. . . 

- What would have happened to districts **with** WB projects had the project **not** been implemented?
- What would have happened to districts **without** WB projects **had** the project been implemented?


## Causal effects

Consider our district under two different counterfactual conditions:



```{r}
#| echo: false
#| fig-align: center
#| fig-width: 10
#| fig-height: 6
#| out-width: "800px"
#| out-height: "400px"

library(grid)

grid.newpage()

# Create viewport
pushViewport(viewport(width = 1, height = 1))

# Left square - Untreated state
grid.rect(x = 0.25, y = 0.55, width = 0.35, height = 0.5, 
          gp = gpar(fill = "gray90", col = "black", lwd = 4))
grid.text("District\n(Untreated)", x = 0.25, y = 0.2, 
          gp = gpar(fontsize = 28))

# Right square - Treated state  
grid.rect(x = 0.75, y = 0.55, width = 0.35, height = 0.5, 
          gp = gpar(fill = "gray90", col = "black", lwd = 4))
grid.text("District\n(Treated)", x = 0.75, y = 0.2, 
          gp = gpar(fontsize = 28))

# Stylized building in the treated state
# Building body
grid.rect(x = 0.75, y = 0.55, width = 0.15, height = 0.28, 
          gp = gpar(fill = "lightblue", col = "black", lwd = 3))
# Roof (triangle approximation using polygon)
grid.polygon(x = c(0.675, 0.75, 0.825), y = c(0.69, 0.76, 0.69),
             gp = gpar(fill = "lightblue", col = "black", lwd = 3))
# Windows
for (wx in c(0.71, 0.79)) {
  for (wy in c(0.46, 0.53, 0.60)) {
    grid.rect(x = wx, y = wy, width = 0.03, height = 0.04,
              gp = gpar(fill = "white", col = "black", lwd = 1))
  }
}

# Label for counterfactual states
grid.text("Two Counterfactual States", x = 0.5, y = 0.05, 
          gp = gpar(fontsize = 32, fontface = "bold"))

popViewport()
```

- WB project $\implies$ treated
- no WB project $\implies$ untreated

. . . 

The only difference between the two conditions is the treatment (project implemented or not), everything else remains unchanged



## Causal effects

Consider our district under two different counterfactual conditions:



```{r}
#| echo: false
#| fig-align: center
#| fig-width: 10
#| fig-height: 6
#| out-width: "800px"
#| out-height: "400px"

library(grid)

grid.newpage()

# Create viewport
pushViewport(viewport(width = 1, height = 1))

# Left square - Untreated state
grid.rect(x = 0.25, y = 0.55, width = 0.35, height = 0.5, 
          gp = gpar(fill = "gray90", col = "black", lwd = 4))
grid.text("District\n(Untreated)", x = 0.25, y = 0.2, 
          gp = gpar(fontsize = 28))

# Right square - Treated state  
grid.rect(x = 0.75, y = 0.55, width = 0.35, height = 0.5, 
          gp = gpar(fill = "gray90", col = "black", lwd = 4))
grid.text("District\n(Treated)", x = 0.75, y = 0.2, 
          gp = gpar(fontsize = 28))

# Stylized building in the treated state
# Building body
grid.rect(x = 0.75, y = 0.55, width = 0.15, height = 0.28, 
          gp = gpar(fill = "lightblue", col = "black", lwd = 3))
# Roof (triangle approximation using polygon)
grid.polygon(x = c(0.675, 0.75, 0.825), y = c(0.69, 0.76, 0.69),
             gp = gpar(fill = "lightblue", col = "black", lwd = 3))
# Windows
for (wx in c(0.71, 0.79)) {
  for (wy in c(0.46, 0.53, 0.60)) {
    grid.rect(x = wx, y = wy, width = 0.03, height = 0.04,
              gp = gpar(fill = "white", col = "black", lwd = 1))
  }
}

# Label for counterfactual states
grid.text("Two Counterfactual States", x = 0.5, y = 0.05, 
          gp = gpar(fontsize = 32, fontface = "bold"))

popViewport()
```


Call $y$ the outcome variable (e.g., health, life expectancy)

. . . 

The **unit causal effect** (or treatment effect) of the project is the difference in $y$ of the district (unit) between the two conditions 

The **average causal effect** (or treatment effect) of the project is the average of the unit treatment effects for all units (all districts)

. . . 

What is the problem here?

## Causality and counterfactuals

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 10
#| fig-height: 6
#| out-width: "800px"
#| out-height: "400px"

library(grid)

grid.newpage()

# Create viewport
pushViewport(viewport(width = 1, height = 1))

# Left square - Untreated state (DASHED - unobserved)
grid.text("UNOBSERVED", x = 0.25, y = 0.88, 
          gp = gpar(fontsize = 20, col = "red", fontface = "italic"))
grid.rect(x = 0.25, y = 0.55, width = 0.35, height = 0.5, 
          gp = gpar(fill = "gray90", col = "black", lwd = 4, lty = "dashed"))
grid.text("District\n(Untreated)", x = 0.25, y = 0.2, 
          gp = gpar(fontsize = 28))

# Right square - Treated state (SOLID - observed)
grid.text("OBSERVED", x = 0.75, y = 0.88, 
          gp = gpar(fontsize = 20, col = "darkgreen", fontface = "italic"))
grid.rect(x = 0.75, y = 0.55, width = 0.35, height = 0.5, 
          gp = gpar(fill = "gray90", col = "black", lwd = 4))
grid.text("District\n(Treated)", x = 0.75, y = 0.2, 
          gp = gpar(fontsize = 28))

# Stylized building in the treated state
# Building body
grid.rect(x = 0.75, y = 0.55, width = 0.15, height = 0.28, 
          gp = gpar(fill = "lightblue", col = "black", lwd = 3))
# Roof (triangle approximation using polygon)
grid.polygon(x = c(0.675, 0.75, 0.825), y = c(0.69, 0.76, 0.69),
             gp = gpar(fill = "lightblue", col = "black", lwd = 3))
# Windows
for (wx in c(0.71, 0.79)) {
  for (wy in c(0.46, 0.53, 0.60)) {
    grid.rect(x = wx, y = wy, width = 0.03, height = 0.04,
              gp = gpar(fill = "white", col = "black", lwd = 1))
  }
}

# Label for counterfactual states
grid.text("Two Counterfactual States", x = 0.5, y = 0.05, 
          gp = gpar(fontsize = 32, fontface = "bold"))

popViewport()
```

The problem is that either the project (the treatment) was implemented or it wasn't. A district (unit) cannot be treated and untreated at the same time. This is the [fundamental problem of causal inference]{.alert}

. . . 

::: {.callout-important title="The fundamental problem of causal inference"}
We cannot observe the same unit under two conditions, so the causal effect for a single unit cannot be observed
:::

. . . 

We also say that the effect for a single unit cannot be [identified]{.alert} from the data

. . . 

What do we do, then?


## Average treatment effects

Suppose projects (treatment) are allocated **randomly** to districts (units)

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 12
#| fig-height: 6
#| out-width: "800px"
#| out-height: "400px"

library(grid)

grid.newpage()

# Create viewport
pushViewport(viewport(width = 1, height = 1))

# Define positions for 4 districts (2x2 grid)
positions <- data.frame(
  x = c(0.25, 0.75, 0.25, 0.75),
  y = c(0.65, 0.65, 0.35, 0.35),
  treated = c(FALSE, TRUE, TRUE, FALSE)  # Districts 2 and 3 are treated
)

# Draw all 4 districts
for (i in 1:4) {
  # Draw rectangle (all solid borders)
  grid.rect(x = positions$x[i], y = positions$y[i], 
            width = 0.3, height = 0.22, 
            gp = gpar(fill = "gray90", col = "black", lwd = 3))
  
  # Add stylized building for treated districts
  if (positions$treated[i]) {
    # Add stylized building for treated districts
    # Building body
    grid.rect(x = positions$x[i], y = positions$y[i], 
              width = 0.08, height = 0.12, 
              gp = gpar(fill = "lightblue", col = "black", lwd = 2))
    # Roof
    grid.polygon(x = c(positions$x[i] - 0.05, positions$x[i], positions$x[i] + 0.05), 
                 y = c(positions$y[i] + 0.06, positions$y[i] + 0.09, positions$y[i] + 0.06),
                 gp = gpar(fill = "lightblue", col = "black", lwd = 2))
    # Windows (smaller)
    for (wx_offset in c(-0.02, 0.02)) {
      for (wy_offset in c(-0.03, 0, 0.03)) {
        grid.rect(x = positions$x[i] + wx_offset, y = positions$y[i] + wy_offset, 
                  width = 0.015, height = 0.018,
                  gp = gpar(fill = "white", col = "black", lwd = 0.5))
      }
    }
  }
}

# Label at bottom
grid.text("Sample of Districts with Treatment Allocated", 
          x = 0.5, y = 0.05, 
          gp = gpar(fontsize = 26, fontface = "bold"))

popViewport()
```

- Districts with WB project $\implies$ treatment group
- Districts without WB project $\implies$ control group

. . . 

With this *random assignment*, we can identify the **average causal effect** of projects in the sample (i.e., the average of unit causal effects)

. . . 

Key intuition: random assignment is "blind" to any differences between units. *On average*, the control group is very similar to the treated group if it were not treated

- Example 1: height 
- Example 2: drug in hospital 

. . . 

In causal inference, we mostly focus on the **ATE** (average treatment effect).



In papers, people sometimes refer to the [ATT]{.hover-note data-tooltip="Average **T**reatment effect on the Treated. This is the average effect for the treated units only, rather than the average effect for all units."} or the [LATE]{.hover-note data-tooltip="Local Average Treatment Effect. This indicates an average effect for some subgroup of units. What subgroup we are talking about depends on the method. Typically, we encounter this term in Instrumental Variables designs, which identify average effects for a specific subgroup of units."}. For this class, just know that they refer to averages of causal effects in the sample of units [(note)]{.hover-note data-tooltip="If you are interested in the differences, see The Effect, Ch.10 https://theeffectbook.net/ch-TreatmentEffects.html"}.



## Estimate an effect under random assignment

If the WB randomizes projects across districts, we can simply compare the average $y$ between the treated and control group.

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| out-height: "400px"    # <--- Forces display size
#| out-width: "auto"      # <--- Maintains aspect ratio
#| 
library(ggdag)
library(ggplot2)

# Create a simple DAG without confounding
dag <- dagify(
  y ~ D,
  coords = list(x = c(D = 1, y = 3),
                y = c(D = 1, y = 1))
)

ggdag(dag) +
  theme_dag_blank() +
  labs(title = "Causal effect: D â†’ Y") +
  theme(plot.title = element_text(hjust = 0.5))
```


We can do this with a *linear regression*.


$y = \alpha + \beta D + \varepsilon$

- $y$ is the development outcome
- $D$ is the variable that indicates a project was implemented (1 if yes, 0 if no)
- $\beta$ is the [ATE]{.hover-note data-tooltip="We could also compute the average of y in the treated group, the average of y in the control group, subtract the two, and obtain the ATE. Mathematically, the difference between the two means and the regression coefficient are identical."}


## Problems of causal inference when we move outside of experiments
 If we want to estimate the effect of a factor $x$ on an outcome $y$ we need a sample of units where $x$ is assigned randomly. The average causal effect of $x$ is the difference in $y$ between the two groups.

 . . . 

 But how likely is it that something is randomly assigned in the real world?

. . . 

 Researchers (doctors and social scientsts) conduct **randomized experiments** to estimate causal effects with certainty

But we social scientists are interested in causal effects (e.g., civil war violence $\rightarrow$ political participation; trade flows $\rightarrow$ growth) where randomization is obviously <u>unfeasible</u> and/or <u>unethical</u>

In these cases, we can only use events and data that have already happened in the world

. . . 

To do causal inference, we need assumptions (called [identification assumptions]{.alert}) about how "randomly" the "treatment" is assigned

. . . 

We can do causal inference only if our assumptions are realistic (i.e., very likely to be satisfied)

This depends on our *knowledge* of the assignment process in the real world


## Estimate an effect under endogeneity

Imagine that the WB decides where to start a project based on local poverty conditions: districts with lower income have a higher probability of being assigned a project.

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-height: "400px"    # <--- Forces display size
#| out-width: "auto"      # <--- Maintains aspect ratio
#| 
library(ggdag)
library(ggplot2)

# Create a DAG with confounding
dag_confounded <- dagify(
  y ~ D + income,
  D ~ income,
  coords = list(x = c(income = 2, D = 1, y = 3),
                y = c(income = 2, D = 1, y = 1))
)

ggdag(dag_confounded, node_size = 20) +
  theme_dag_blank() +
  labs(title = "DAG with confounding: Income affects both D and Y") +
  theme(plot.title = element_text(hjust = 0.5))
```


. . . 

If we simply compare treated and non-treated districts as before, and run $y=\alpha + \beta D + \varepsilon$, our $\beta$ will be
$$\beta= \underbrace{\text{ATE}}_{\text{causal effect}} + \underbrace{\text{pre-existing income differences}}_{\text{bias}}$$


. . . 

Intuition: if two things change at the same time, we are not sure which one was the cause

. . . 

We call this a problem of [*selection*]{.hover-note data-tooltip="Selection in this case means 'selection into treatment', that is units choose to be treated, or are chosen to be treated, for non-random reasons."} or [*endogeneity*]{.hover-note data-tooltip="Endogeneity means that the treatment assignment depends on some characteristics of the units (it is 'endogenous' to the units themselves). Its contrary, Exogeneity, means that the treatment is independent of the unit characteristics, or random."} or [*confounding*]{.hover-note data-tooltip="Meaning that if we ignore the income variable, it will confound our estimate of the ATE."} or [*omitted variable*]{.hover-note data-tooltip="Income is the variable that gives us problems if omitted."}.

This is what we mean when we say that <u>correlation is not causation</u>

## Estimate an effect under endogeneity

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-height: "400px"    
#| out-width: "auto"      
#| 
library(ggdag)
library(ggplot2)

# Create a DAG with confounding
dag_confounded <- dagify(
  y ~ D + income,
  D ~ income,
  coords = list(x = c(income = 2, D = 1, y = 3),
                y = c(income = 2, D = 1, y = 1))
)

ggdag(dag_confounded, node_size = 20) +
  theme_dag_blank() +
  labs(title = "DAG with confounding: Income affects both D and Y") +
  theme(plot.title = element_text(hjust = 0.5))
```

To remove the bias, we can include the income variable in the regression: in this way we "keep it constant" and compare units with the same value of income

$y = \alpha + \beta D + \gamma \text{Income} + \varepsilon$

and now 

$\beta=\text{ATE}$


## Common forms of endogeneity

```{r}
#| echo: false
#| fig-width: 12
#| fig-height: 4
#| layout-ncol: 2

library(ggdag)
library(ggplot2)
library(patchwork)

# DAG 1: Confounding with generic confounder
dag_confounding <- dagify(
  y ~ D + C,
  D ~ C,
  coords = list(x = c(C = 2, D = 1, y = 3),
                y = c(C = 2, D = 1, y = 1))
)

plot1 <- ggdag(dag_confounding) +
  theme_dag_blank() +
  labs(title = "Common cause") +
  theme(plot.title = element_text(hjust = 0.5))

# DAG 2: Reverse causality
dag_reverse <- dagify(
  D ~ y,
  coords = list(x = c(D = 1, y = 3),
                y = c(D = 1, y = 1))
)

plot2 <- ggdag(dag_reverse) +
  theme_dag_blank() +
  labs(title = "Reverse causality") +
  theme(plot.title = element_text(hjust = 0.5))

# Combine plots side by side
plot1 | plot2
```


- Common cause: some other variable is causing both the treatment and the outcome
- Reverse causality: the outcome causes the treatment and not vice-versa

## Causal research design

In this example, we imagined we knew the source of endogeneity or confounding: income. Therefore, when we compare units with the same income level, treatment is random between them

. . . 

If we planned this study before collecting the data, our [research design]{.alert} would be based on this assumption and we would plan to run a linear regression controlling for income to cleanly estimate the ATE

. . . 

Now, in your mind, replace "WB projects" with "civil war" or "trade flows". You immediately see how complex the assignment process is for real-world "treatments" and how likely endogeneity is

. . . 

To make causal claims on these topics we have to design our analyses thinking carefully about the assignment process in the real world to overcome endogeneity

We can look for details of the actual assignment process to "find" the appropriate counterfactuals in the data


# Common Research Designs in IPE {.section}

## Randomized experiments

The "gold standard" of causal inference. Treatment assignment (and identification) is controlled by the researcher 

. . . 

Less common in IPE than in other fields (because IPE is mostly concerned with things that "cross borders")

- <u>Field experiments</u>. Treatment administration and outcome measurement happen in the real world.
    - Most common in medical research
    - Commonly used in [American Politics]{.hover-note data-tooltip="A classic application is Get Out The Vote experiments, where scholars randomize and examine the impacts of communication strategies to increase turnout."}, [Comparative Politics]{.hover-note data-tooltip="For instance, scholars may randomize information campaigns about politicians' behavior and examine whether this impacts voter choice."}, [Development Economics]{.hover-note data-tooltip="Experiments have become the main tools economists use to study the impact of development policy. See the 2019 Nobel Prize in Economic Sciences."}
- <u>Survey experiments</u>. Treatment administration and outcome measurement happen within a survey.
    - Longer tradition in political science to study public opinion
    - Used to understand how information or communication affects voters' attitudes or opinions 
    - Measures psychological mechanisms rather than real-world effects
- <u>Lab experiments</u>. Treatment administration and outcome measurement happen in an artificial lab setting.
    - Stronger tradition in economics
    - Used to understand decision-making in strategic interactions




## Natural experiments

Circumstances in the real world where something "happens by chance"

. . . 

Such circumstances exist, especially in nature (e.g., earthquakes). In the human world they are hardly credible without further qualifications

. . . 

The question to ask is always: who "decides" the treatment? What do they know? What are their goals?

. . . 

The answer to this question reveals plausible research designs



## Selection on observables

If we believe that the "endogeneity" of treatment is due to known, observed variables, we can collect them and "control" for them

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-height: "400px"    
#| out-width: "auto"      
#| 
library(ggdag)
library(ggplot2)

# Create a DAG with confounding
dag_confounded <- dagify(
  y ~ D + C,
  D ~ C,
  coords = list(x = c(C = 2, D = 1, y = 3),
                y = c(C = 2, D = 1, y = 1))
)

ggdag(dag_confounded, node_size = 20) +
  theme_dag_blank() +
  labs(title = "Selection on observables: C causes D and Y") +
  theme(plot.title = element_text(hjust = 0.5))
```

This is analogous to running little experiments between units with the same values of the variables, and taking the average of the effects from these experiments.

. . . 

Different ways to do it:

- <u>Linear regression</u>. The confounding variables are included in the regression as independent variables.

$y = \alpha + \beta D + \gamma \text{(control variables)} + \varepsilon$

- <u>Matching</u>. Other techniques to compare "more similar" units, following a similar logic to "controlling". We will not go into the details in this class. If you find them, just know that they are similar to controlling.


## Instrumental variables

If we believe that the "endogeneity" of treatment is due to unobserved variables, control is insufficient (we lack the control variables). An [instrumental variable]{.alert} can solve this problem

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| out-height: "400px"    
#| out-width: "auto"      
#| 
library(ggdag)
library(ggplot2)

# Create an IV DAG
dag_iv <- dagify(
  y ~ D + C,
  D ~ Z + C,
  coords = list(x = c(Z = 1, C = 2.5, D = 2, y = 4),
                y = c(Z = 2, C = 3, D = 1, y = 1))
)

ggdag(dag_iv) +
  theme_dag_blank() +
  labs(title = "Instrumental Variables: Z causes D, D causes Y, but Z does not directly cause Y") +
  theme(plot.title = element_text(hjust = 0.5, size = 12))
```

An instrumental variable (or just an instrument) is a variable that is exogenous/random and has a causal effect on the treatment variable. Conceptually, it is a random "push" to accept the treatment

. . . 

Under some assumptions, we can estimate an average causal effect by "instrumenting" the endgenous treatment with the exogenous instrumental variable



## Instrumental variables

If we believe that the "endogeneity" of treatment is due to unobserved variables, control is insufficient (we lack the control variables). An [instrumental variable]{.alert} can solve this problem

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| out-height: "400px"    
#| out-width: "auto"      
#| 
library(ggdag)
library(ggplot2)

# Create an IV DAG
dag_iv <- dagify(
  y ~ D + C,
  D ~ Z + C,
  coords = list(x = c(Z = 1, C = 2.5, D = 2, y = 4),
                y = c(Z = 2, C = 3, D = 1, y = 1))
)

ggdag(dag_iv) +
  theme_dag_blank() +
  labs(title = "Instrumental Variables: Z causes D, D causes Y, but Z does not directly cause Y") +
  theme(plot.title = element_text(hjust = 0.5, size = 12))
```



$$\underbrace{D}_{\text{endogenous treatment}} = \delta + \theta \underbrace{Z}_{\text{instrument}} + \phi X + u \quad \text{(First stage)}$$

$$y = \alpha + \beta \underbrace{D}_{\text{endogenous treatment}} + \gamma X + \varepsilon \quad \text{(Second stage)}$$

. . . 

The statistical model estimates the first equation (first stage), then predicts the values of $D$ and replaces the observed values of $D$ in the second equation (second stage) with the predicted values.

This is equivalent to "controlling" for the endogenous part of the treatment $D$ and using only the exogenous part of the treatment to estimate the ATE.



## Instrumental variables

Examples of IV designs

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| out-height: "400px"    
#| out-width: "auto"      
#| 
library(ggdag)
library(ggplot2)

# Create an IV DAG
dag_iv <- dagify(
  y ~ D + C,
  D ~ Z + C,
  coords = list(x = c(Z = 1, C = 2.5, D = 2, y = 4),
                y = c(Z = 2, C = 3, D = 1, y = 1))
)

ggdag(dag_iv) +
  theme_dag_blank() +
  labs(title = "Instrumental Variables: Z causes D, D causes Y, but Z does not directly cause Y") +
  theme(plot.title = element_text(hjust = 0.5, size = 12))
```

::: {.panel-tabset}

### Example 1

| Research Question | Treatment | Instrument | Outcome |
|-------------------|-----------|------------|---------|
| Does social pressure increase turnout? | Reading an appeal to vote | Randomized postcard with an appeal | Individual turnout |

### Example 2

| Research Question | Treatment | Instrument | Outcome |
|-------------------|-----------|------------|---------|
| Does education improve earnings? | Years of schooling | Quarter of birth | Annual income |

### Example 3

| Research Question | Treatment | Instrument | Outcome |
|-------------------|-----------|------------|---------|
| Do trade policies affect growth? | Free trade agreement | Geographic proximity | GDP per capita |

### Example 4

| Research Question | Treatment | Instrument | Outcome |
|-------------------|-----------|------------|---------|
| Does economic growth reduce civil conflict? | GDP per capita growth | Rainfall variation | Civil conflict incidence |



:::


## Instrumental variables

IV design requires assumptions. The ones that are relevant for us at this stage are:


- The instrument is random (or random after controlling for covariates)
- The instrument has an effect on the treatment
- The instrument has an effect on the outcome <u>only through the treatment</u>. This is called the [Exclusion restriction]{.alert}

. . . 

There are other assumptions which are more technical, we will not go through them. You find the discussion in Keele's reading for today.


## Other research designs: DID and RDD

For reference. We will go back to them if needed.

```{r, fig.show = 'hold', out.width = '100%'}
#| #label: fig-mpg
#| #fig-cap: "Empirical strategies"
#| fig-subcap:
#|   - "Difference-in-Differences"
#|   - "Regression Discontinuity"
#| layout-ncol: 2
#| # column: page

# Load necessary package
library(ggplot2)


##### DID plot #####
# Set up data
data <- data.frame(
  group = rep(c("Control", "Treated"), each = 2),
  time = rep(c("Before", "After"), 2),
  outcome = c(5, 6, 6, 8)  # Example values
)

# Counterfactual trend for the Treated group (dashed line)
counterfactual <- data.frame(
  group = "Treated (Counterfactual)",
  time = c("Before", "After"),
  outcome = c(6, 7)  # Parallel shift following Control group trend
)

# Define y-values for the square bracket
y_treated_after <- 8  # Observed outcome for Treated group (After)
y_counterfactual_after <- 7  # Counterfactual outcome for Treated group (After)

# Plot
ggplot(data, aes(x = time, y = outcome, group = group, color = group)) +
  geom_line(size = 1) +  # Solid lines for observed trends
  geom_point(size = 3) +  # Points at data values
  geom_line(data = counterfactual, aes(x = time, y = outcome), 
            linetype = "dashed", color = "black", size = 1) +  # Dashed counterfactual trend
  geom_vline(xintercept = 1.5, linetype = "dotted", color = "red", size = 1) +  # Treatment time
  scale_x_discrete(limits = c("Before", "After")) +
  labs(title = "",
       x = "Time Period", y = "Outcome",
       color = "Group") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  
  # Add square bracket for DiD treatment effect
  geom_segment(aes(x = 2.1, xend = 2.1, y = y_counterfactual_after, yend = y_treated_after), 
               color = "red", size = 1.2) +  # Vertical line of bracket
  geom_segment(aes(x = 2.0, xend = 2.1, y = y_counterfactual_after, yend = y_counterfactual_after), 
               color = "red", size = 1.2) +  # Bottom horizontal line
  geom_segment(aes(x = 2.0, xend = 2.1, y = y_treated_after, yend = y_treated_after), 
               color = "red", size = 1.2) +  # Top horizontal line
  annotate("text", x = 2.15, y = (y_counterfactual_after + y_treated_after) / 2, 
           label = "ATT", color = "red", size = 5, hjust = 0)

##### RDD plot #####

# Set up data
set.seed(123)  # For reproducibility
x <- seq(-2, 2, by = 0.1)  # Running variable (centered at 0)
y_control <- 2 + 1.5 * x   # Outcome for control group (linear)
y_treated <- y_control + 2 # Outcome for treated group (discontinuity at 0)

# Find y-values at cutoff (x = 0)
y_cutoff_control <- 2 + 1.5 * 0  # y = 2
y_cutoff_treated <- y_cutoff_control + 2  # y = 4

# Define colors (same as in the DiD plot)
treatment_color <- "#1b9e77"  # Green
control_color <- "#d95f02" # Orange

# Create a data frame
data <- data.frame(
  x = rep(x, 2),
  y = c(y_control, y_treated),
  group = rep(c("Control", "Treated"), each = length(x))
)

# Base plot
p <- ggplot(data, aes(x = x, y = y, color = group)) +
  geom_line(data = subset(data, x < 0 & group == "Control"), size = 1.2) +  # Solid for control (before cutoff)
  geom_line(data = subset(data, x >= 0 & group == "Treated"), size = 1.2) + # Solid for treated (after cutoff)
  geom_line(data = subset(data, x >= 0 & group == "Control"), size = 1.2, linetype = "dashed") + # Counterfactual for control
  geom_line(data = subset(data, x < 0 & group == "Treated"), size = 1.2, linetype = "dashed") + # Counterfactual for treated
  geom_vline(xintercept = 0, linetype = "dotted", size = 1) +  # Cutoff line
  scale_color_manual(values = c("Control" = control_color, "Treated" = treatment_color)) + 
  labs(
    title = ")",
    x = "Distance to the cutoff",
    y = "Outcome",
    color = "Group"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

# Add a square bracket to indicate the discontinuity
p + 
  geom_segment(aes(x = 0.15, xend = 0.15, y = y_cutoff_control, yend = y_cutoff_treated), 
               color = "red", size = 1.2) +  # Vertical line of bracket
  geom_segment(aes(x = 0.1, xend = 0.15, y = y_cutoff_control, yend = y_cutoff_control), 
               color = "red", size = 1.2) +  # Bottom horizontal line
  geom_segment(aes(x = 0.1, xend = 0.15, y = y_cutoff_treated, yend = y_cutoff_treated), 
               color = "red", size = 1.2) +  # Top horizontal line
  annotate("text", x = 0.2, y = 0.5 + (y_cutoff_control + y_cutoff_treated) / 2, 
           label = "LATE", color = "red", size = 5, hjust = 0)


```

**Difference-in-Differences**

- The treated group is treated at some point in time
- We observe the treated and control group before and after the treated group receives the treatment
- For each group, we subtract the outcome after treatment to the outcome before treatment (first difference). The we subtract the first difference of the control group from the first difference of the treated group (diff-in-diff)

. . . 

**Regression Discontinuity**

- Treatment is given according to the value of some variable
- Only units with a value above/below a given cutoff point receive treatment
- We compare only units very close to the cutoff point to approximate a randomized experiment


